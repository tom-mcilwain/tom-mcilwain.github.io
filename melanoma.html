<!DOCTYPE HTML>
<!--
	Phantom by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Binary Classification of Melanoma</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">
		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<div class="inner">

							<!-- Logo -->
								<a href="index.html" class="logo">
									<span class="symbol"><img src="images/IMG_0175.PNG" alt="" /></span><span class="title">TOM MCILWAIN</span>
								</a>
				
							<!-- Nav -->
								<nav>
									<ul>
										<li><a href="#menu">Menu</a></li>
									</ul>
								</nav>

						</div>
					</header>

				<!-- Menu -->
					<nav id="menu">
						<h2>Menu</h2>
						<ul>
							<li><a href="index.html">Home</a></li>
							<li><a href="generic.html">Ipsum veroeros</a></li>
							<li><a href="generic.html">Tempus etiam</a></li>
							<li><a href="generic.html">Consequat dolor</a></li>
							<li><a href="elements.html">Elements</a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">
						<div class="inner">
							<h1>A Two-Step, Two-Pronged Approach to Binary Classification of Melanoma</h1>
							<h2>CS 230: Deep Learning</h2>
							<h2>Stanford Computer Science, September-December 2021</h2>
							<h5>Abstract</h5>
              						<p>Screening for skin cancer involves either an external examination by a physician or a biopsy of the lesion. These methods are either subjective or invasive, therefore there is a need for an effective screening technique that does not involve subjective examination or invasive techniques. Many people have turned to deep learning as a solution to this problem. Many existing methods include training CNN ensemble models, image segmentation, adding metadata, and using transfer learning in order to improve classification accuracy [3]. In this paper, we use the SIIC-ISIC 2020 Challenge dataset and take a two-step, two-pronged approach to binary classification of images of skin lesions as either melanoma or no melanoma [4]. The first step involves using a U-Net trained on the HAM10000 dataset to produce masks of the images of the ISIC2020 dataset prior to CNN input [5-7]. The mask and image are then concatenated and inputted into a CNN architecture. Based on literature exploration, we implement a VGG model, a Siamese model adopted from Messina et al, and an EfficientNet model that was used in the winning solution to achieve an AUC of 0.9442 [12, 15]. Additionally, we concatenate one-hot-encoded metadata and the output of the CNN model and put it into a final two-layer Dense network. Our best CNN architecture is the Siamese model, and combined with the rest of the pipeline, achieved a test AUC score of 0.831. The results show the potential for a combination of methods and pipelines to be used in binary image classification for skin lesions. Further work is needed to truly explore how a two-step, two-pronged approach can be best engineered.</p>
							<h5>Introduction</h5>
							<p>The usual method of screening skin disorders is either via external examination by a physician or a biopsy, in which a scraping or snipped part of the skin is used to determine the proper class of skin lesion. These methods are quite subjective and thus not very effective. There is a need for an effective screening technique that does not involve subjective examination or invasive techniques. For example, squamous cell carcinoma is often misdiagnosed as basal cell carcinoma which is less dangerous, ultimately delaying time to proper treatment [1]. Melanoma is another type of skin cancer that is often misdiagnosed; physician diagnosis is only accurate roughly 65-80% of the time [2]. The current screening technique, involving physicians and other providers examining the skin of patients, is very subjective and can depend heavily on experience.</p>
							<p>Therefore many people have turned to deep learning as a solution to this problem. Using computer vision, there is potential to improve screening of skin lesions so that patients do not have to go through an invasive procedure and more dangerous types of cancers are caught earlier. By predicting the level of danger of a skin lesion that is presented via an image, we can both eliminate patient discomfort and decrease subjectivity during screening. In the real world, patients could take pictures of their skin lesion and use an app to determine the severity of the lesion, thereby enabling them to take further action if indicated as dangerous.</p>
							<p>Classification of skin lesions using deep learning is an application that has been widely explored. Many methods include training ensemble models, segmentation, including metadata, and transfer learning in order to improve classification accuracy [3]. In this paper, a U-net is first used to segment and mask skin lesions. Binary classification of lesions (benign vs. malignant) is the next step. Various CNN architectures are tested combined with a fully connected network that takes as input metadata of the image including patient sex, age, and location of the lesion. These approaches are all based in literature and are implemented using the SIIM-ISIC (International Skin Imaging Collaboration) Melanoma Classification Challenge competition dataset from 2020 [4].</p>
							<h5>Related Work</h5>
							<p>There is a lot of previous work related to this application. A systematic review paper that analyzed 13 different skin cancer classification techniques using CNNs found that fit into two broad approaches: CNN as a feature extractor, and transfer learning with ensemble models [3].</p>
							<p><b>Feature Extractor</b>   Using CNNs as a feature extracting tools has been used in relation to skin cancer classification. For example, the HAM10000 dataset (ISIC 2018 dataset) included masks for each skin lesion that identified the location of the lesion within the image [5]. One team integrated a U-net directly into their classification architecture and achieved 93.1% accuracy, a sensitivity of 94.9%, and a specificity of 92.8% for classifying melanoma versus non-melanoma [6]. A U-net is a CNN architecture that was built for biomedical image segmentation [7]. The architecture of a U-net can be seen in figure 1 (left). In this paper, we build off of some of these techniques and implement a U-net trained on the HAM10000 dataset before using it to segment the skin lesion images from the SIIM-ISIC 2020 competition dataset prior to classification.</p>
							<p><b>Transfer Learning and Ensembles</b>   Some high-performing models for skin lesion classification are built from scratch based roughly on previous CNN architectures. Many commonly used existing pre-trained CNN architectures in biomedical image classification applications include MobileNet, ResNet, EfficientNet, VGG, Inception, Xception, and GoogLeNet [8-12]. For example, Bi et al entered the ISIC 2017 challenge and used a pre-trained ResNet in a two-step approach to image classification; first perform lesion segmentation then lesion classification. They achieved an average binary AUC of 91.3 [11]. Additionally, the winning solution to the SIIM-ISIC 2020 challenge used an ensemble of 18 different EfficientNet models pre-trained on ImageNet, some with metadata as additional input into the network [12]. They combined the CNN ensemble model fit on the images and a two-layer dense network fit on image metadata (such as sex, age, lesion location). The architecture of their metadata models can be seen in figure 1 (center). Their ensemble achieved a test AUC of 0.9442. Since we are using the same dataset, this is the metric that we are trying to beat. In this paper, we use a similar solution and evaluate various CNN models (including pre-trained models) and a two-layer dense architecture trained on metadata to classify skin lesions as benign or malignant (melanoma vs. no melanoma).</p>
							<p><b>Training from Scratch</b>   A few papers have demonstrated use of CNN architectures that have been trained from scratch and have been successful in biomedical applications. For example, Nasr-Esfahani et al used a k-means classifier for segmentation and a two-layer CNN model images to classify lesions as melanoma vs. benign [13]. They trained the model on 136 images and achieved a sensitivity of 81%, a specificity of 80%, and an accuracy of 81%. Another example of training from scratch is from Spasov et al who used a Siamese-type CNN architecture for classification of MRI scans regarding Alzheimerâ€™s disease [14]. Messina et al adopted this architecture and simplified it for their purposes [15]. Notably, their input was masked MRI images, similar to the input used in the present study. Thearchitecture Messina et al implemented can be found in figure 1 (right). In this paper, we evaluate the use of the Siamese model in binary image classification.</p>
						</div>
					</div>

				<!-- Footer -->
					<footer id="footer">
						<div class="inner">
							<section>
								<h2>Get in touch</h2>
								<form method="post" action="#">
									<div class="fields">
										<div class="field half">
											<input type="text" name="name" id="name" placeholder="Name" />
										</div>
										<div class="field half">
											<input type="email" name="email" id="email" placeholder="Email" />
										</div>
										<div class="field">
											<textarea name="message" id="message" placeholder="Message"></textarea>
										</div>
									</div>
									<ul class="actions">
										<li><input type="submit" value="Send" class="primary" /></li>
									</ul>
								</form>
							</section>
							<section>
								<h2>Follow</h2>
								<ul class="icons">
									<li><a href="#" class="icon brands style2 fa-twitter"><span class="label">Twitter</span></a></li>
									<li><a href="#" class="icon brands style2 fa-facebook-f"><span class="label">Facebook</span></a></li>
									<li><a href="#" class="icon brands style2 fa-instagram"><span class="label">Instagram</span></a></li>
									<li><a href="#" class="icon brands style2 fa-dribbble"><span class="label">Dribbble</span></a></li>
									<li><a href="#" class="icon brands style2 fa-github"><span class="label">GitHub</span></a></li>
									<li><a href="#" class="icon brands style2 fa-500px"><span class="label">500px</span></a></li>
									<li><a href="#" class="icon solid style2 fa-phone"><span class="label">Phone</span></a></li>
									<li><a href="#" class="icon solid style2 fa-envelope"><span class="label">Email</span></a></li>
								</ul>
							</section>
							<ul class="copyright">
								<li>&copy; Untitled. All rights reserved</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
